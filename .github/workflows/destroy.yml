name: destroy

on:
  workflow_dispatch:
    inputs:
      delete_backend:
        description: "Also delete TF backend (S3 bucket + DynamoDB table)? DANGEROUS"
        required: false
        default: "no"

env:
  AWS_REGION: us-east-1
  ACCOUNT_ID: "156041402173"
  CLUSTER_NAME: devsecops
  K8S_NAMESPACE: devsecops
  TF_BACKEND_BUCKET: devsecops-156041402173-us-east-1
  TF_BACKEND_KEY: tfstate/infra.tfstate
  TF_LOCK_TABLE: terraform-locks
  TERRAFORM_ROLE_ARN: arn:aws:iam::156041402173:role/devsecops-terraform-role
  ECR_REPO: devsecops

permissions:
  id-token: write
  contents: read

jobs:
  nuke-infra-safely:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: "Configure AWS"
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.TERRAFORM_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      # 0) Clear any stale TF lock row first (best-effort)
      - name: "Clear stale DynamoDB lock (best-effort)"
        shell: bash
        continue-on-error: true
        run: |
          LOCK_KEY="${TF_BACKEND_BUCKET}/${TF_BACKEND_KEY}"
          aws dynamodb delete-item --table-name "$TF_LOCK_TABLE" --key "{\"LockID\":{\"S\":\"$LOCK_KEY\"}}"

      # 1) Delete Kubernetes resources (drops ELB to stop cost)
      - name: "Install kubectl"
        shell: bash
        run: |
          curl -sL "https://dl.k8s.io/release/$(curl -sL https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl" -o kubectl
          install -m 0755 kubectl /usr/local/bin/kubectl
          kubectl version --client=true

      - name: "Delete Kubernetes manifests (ok if cluster/files missing)"
        shell: bash
        continue-on-error: true
        run: |
          rm -f ~/.kube/config
          aws eks update-kubeconfig --name "$CLUSTER_NAME" --region "$AWS_REGION" || exit 0
          if [ -d k8s ]; then
            kubectl delete -f k8s/ --ignore-not-found=true || true
          fi
          # Wait a bit for ELB release
          sleep 60

      # 2) Purge all ECR images so repo can be deleted cleanly
      - name: "Purge all ECR images (best-effort)"
        shell: bash
        continue-on-error: true
        run: |
          set -e
          sudo apt-get update -y >/dev/null 2>&1 || true
          sudo apt-get install -y jq >/dev/null 2>&1 || true
          REPO="$ECR_REPO"
          echo "Purging images in ECR repo: $REPO"
          NEXT=""
          while :; do
            if [ -n "$NEXT" ]; then
              PAGE=$(aws ecr list-images --repository-name "$REPO" --max-results 1000 --next-token "$NEXT" 2>/dev/null || true)
            else
              PAGE=$(aws ecr list-images --repository-name "$REPO" --max-results 1000 2>/dev/null || true)
            fi
            IDS=$(echo "$PAGE" | jq -c '.imageIds // []')
            COUNT=$(echo "$IDS" | jq 'length')
            [ "$COUNT" -eq 0 ] && break
            aws ecr batch-delete-image --repository-name "$REPO" --image-ids "$IDS" || true
            NEXT=$(echo "$PAGE" | jq -r '.nextToken // empty')
            [ -z "$NEXT" ] && break
          done
          echo "ECR purge done (or repo absent)."

      # 3) Terraform destroy using S3/Dynamo backend
      - name: "Setup Terraform"
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.9.5

      - name: "Write backend stub (S3)"
        shell: bash
        run: |
          mkdir -p infra
          cat > infra/backend.tf <<'HCL'
          terraform {
            backend "s3" {}
          }
          HCL

      - name: "Terraform Init"
        shell: bash
        run: |
          terraform -chdir=infra init -upgrade \
            -backend-config="bucket=${TF_BACKEND_BUCKET}" \
            -backend-config="key=${TF_BACKEND_KEY}" \
            -backend-config="region=${AWS_REGION}" \
            -backend-config="dynamodb_table=${TF_LOCK_TABLE}" \
            -backend-config="encrypt=true"

      # keep backend bucket/table: remove storage module from STATE so destroy won't touch it
      - name: "Keep backend bucket: drop storage module from state"
        shell: bash
        continue-on-error: true
        run: |
          terraform -chdir=infra state list | awk '/^module\.storage\./{print}' | \
            while read -r addr; do
              echo "Removing from state: $addr"
              terraform -chdir=infra state rm "$addr" || true
            done

      - name: "Terraform Plan (destroy)"
        shell: bash
        run: terraform -chdir=infra plan -destroy -lock-timeout=10m -out=tfplan

      - name: "Terraform Apply (destroy)"
        shell: bash
        run: terraform -chdir=infra apply -lock-timeout=10m -auto-approve tfplan

      # 4) Clean up lock row again, just in case
      - name: "Delete DynamoDB lock row (best-effort)"
        shell: bash
        continue-on-error: true
        run: |
          LOCK_KEY="${TF_BACKEND_BUCKET}/${TF_BACKEND_KEY}"
          aws dynamodb delete-item --table-name "$TF_LOCK_TABLE" --key "{\"LockID\":{\"S\":\"$LOCK_KEY\"}}" >/dev/null 2>&1 || true

      # 5) (Optional) delete backend itself (DANGEROUS)
      - name: "Delete backend bucket & lock table (DANGEROUS)"
        if: ${{ github.event.inputs.delete_backend == 'yes' }}
        shell: bash
        continue-on-error: true
        run: |
          sudo apt-get update -y >/dev/null 2>&1 || true
          sudo apt-get install -y jq >/dev/null 2>&1 || true
          BUCKET="${TF_BACKEND_BUCKET}"
          PREFIX_EXCLUDE="^${TF_BACKEND_KEY}"
          echo "Emptying versioned bucket $BUCKET (this will remove ALL versions except tfstate by default)..."
          aws s3api list-object-versions --bucket "$BUCKET" --output json \
            | jq -c '.Versions[]?, .DeleteMarkers[]? | {Key:.Key, VersionId:.VersionId}' \
            | while read -r item; do
                KEY=$(echo "$item" | jq -r .Key)
                VID=$(echo "$item" | jq -r .VersionId)
                if echo "$KEY" | grep -Eq "$PREFIX_EXCLUDE"; then
                  continue  # keep state by default
                fi
                aws s3api delete-object --bucket "$BUCKET" --key "$KEY" --version-id "$VID" || true
              done
          aws s3 rb "s3://${TF_BACKEND_BUCKET}" --force || true
          aws dynamodb delete-table --table-name "$TF_LOCK_TABLE" || true

      - name: "Cost hotspots checklist"
        shell: bash
        run: |
          echo "Check in AWS Console for stragglers:"
          echo "- NAT Gateways (VPC/NAT) -> should be gone with VPC"
          echo "- Load Balancers -> EC2/Load Balancers"
          echo "- EBS Volumes / Elastic IPs -> EC2"
          echo "- ECR repo should be empty or deleted"
