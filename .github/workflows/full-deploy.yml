name: full-deploy

on:
  push:
    branches: ["main"]
    paths:
      - 'infra/**'
  workflow_dispatch: {}

env:
  AWS_REGION: us-east-1
  ACCOUNT_ID: "156041402173"
  ECR_REGISTRY: 156041402173.dkr.ecr.us-east-1.amazonaws.com
  ECR_REPO: devsecops
  CLUSTER_NAME: devsecops
  K8S_NAMESPACE: devsecops
  TF_BACKEND_BUCKET: devsecops-156041402173-us-east-1
  TF_BACKEND_KEY: tfstate/infra.tfstate
  TF_LOCK_TABLE: terraform-locks
  PYTHONPATH: .

permissions:
  id-token: write
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  infra-build-deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # ---- Tests + scan -----------------------------------------------------
      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install deps
        run: |
          python -m venv venv
          . venv/bin/activate
          pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install -q pytest bandit

      - name: Run tests
        run: |
          . venv/bin/activate
          python -m pytest -q

      - name: Security scan (bandit)
        run: |
          . venv/bin/activate
          if [ -d app ]; then bandit -r app -ll || true; fi

      # ---- AWS creds --------------------------------------------------------
      - name: Configure AWS (assume Terraform role)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::156041402173:role/devsecops-terraform-role
          aws-region: ${{ env.AWS_REGION }}

      # âœ… Install Terraform (fixes "terraform: command not found")
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.9.5

      # ---- Remote Terraform state (S3 + DynamoDB) --------------------------
      - name: Ensure DynamoDB lock table exists
        run: |
          aws dynamodb describe-table --table-name "$TF_LOCK_TABLE" >/dev/null 2>&1 \
            || aws dynamodb create-table \
                 --table-name "$TF_LOCK_TABLE" \
                 --attribute-definitions AttributeName=LockID,AttributeType=S \
                 --key-schema AttributeName=LockID,KeyType=HASH \
                 --billing-mode PAY_PER_REQUEST
          echo "Lock table ready: $TF_LOCK_TABLE"

      - name: Write backend stub (S3)
        run: |
          cat > infra/backend.tf <<'HCL'
          terraform {
            backend "s3" {}
          }
          HCL

      - name: Terraform Init (S3 backend)
        run: |
          terraform -chdir=infra init -upgrade \
            -backend-config="bucket=${TF_BACKEND_BUCKET}" \
            -backend-config="key=${TF_BACKEND_KEY}" \
            -backend-config="region=${AWS_REGION}" \
            -backend-config="dynamodb_table=${TF_LOCK_TABLE}" \
            -backend-config="encrypt=true"

      # ---- Adopt existing resources so TF won't recreate --------------------
      - name: Import pre-existing core resources (idempotent)
        run: |
          set -e
          cd infra
          imp () { local addr="$1" id="$2"; terraform state list | grep -q "^${addr}$" || terraform import "$addr" "$id" >/dev/null 2>&1 || true; }

          # ECR repository
          if aws ecr describe-repositories --repository-names "${{ env.ECR_REPO }}" --region "${{ env.AWS_REGION }}" >/dev/null 2>&1; then
            imp "module.ecr.aws_ecr_repository.this" "${{ env.ECR_REPO }}"
          fi

          # GitHub Actions IAM role
          if aws iam get-role --role-name "devsecops-github-actions-role" >/dev/null 2>&1; then
            imp "module.github_oidc.aws_iam_role.github_actions" "devsecops-github-actions-role"
          fi

          # EKS cluster IAM role (if already exists)
          if aws iam get-role --role-name "devsecops-eks-cluster-role" >/dev/null 2>&1; then
            imp "module.eks.aws_iam_role.cluster" "devsecops-eks-cluster-role"
          fi

          # Nodegroup IAM role
          if aws iam get-role --role-name "devsecops-eks-cluster-node-role" >/dev/null 2>&1; then
            imp "module.eks.aws_iam_role.node" "devsecops-eks-cluster-node-role"
          fi

      - name: Adopt existing VPC & subnets if found (idempotent)
        run: |
          set -e
          cd infra

          # Find VPC by Name tag + CIDR
          VPC_NAME="devsecops-vpc"
          CIDR="10.0.0.0/16"
          VPC_ID=$(aws ec2 describe-vpcs \
            --filters Name=tag:Name,Values="$VPC_NAME" Name=cidr-block,Values="$CIDR" \
            --query 'Vpcs[0].VpcId' --output text || true)

          imp () { local addr="$1" id="$2"; terraform state list | grep -q "^${addr}$" || terraform import "$addr" "$id" >/dev/null 2>&1 || true; }

          if [ -n "$VPC_ID" ] && [ "$VPC_ID" != "None" ]; then
            echo "Found VPC $VPC_ID ($VPC_NAME). Adopting into state."
            imp "module.vpc.aws_vpc.this" "$VPC_ID"

            for AZ in us-east-1a us-east-1b; do
              PUB_NAME="devsecops-public-$AZ"
              PRV_NAME="devsecops-private-$AZ"

              PUB_ID=$(aws ec2 describe-subnets --filters Name=vpc-id,Values="$VPC_ID" Name=tag:Name,Values="$PUB_NAME" --query 'Subnets[0].SubnetId' --output text || true)
              PRV_ID=$(aws ec2 describe-subnets --filters Name=vpc-id,Values="$VPC_ID" Name=tag:Name,Values="$PRV_NAME" --query 'Subnets[0].SubnetId' --output text || true)

              if [ -n "$PUB_ID" ] && [ "$PUB_ID" != "None" ]; then
                imp "module.vpc.aws_subnet.public[$AZ]" "$PUB_ID"
              fi
              if [ -n "$PRV_ID" ] && [ "$PRV_ID" != "None" ]; then
                imp "module.vpc.aws_subnet.private[$AZ]" "$PRV_ID"
              fi
            done
          else
            echo "No existing VPC found (tag=$VPC_NAME, cidr=$CIDR). Terraform will create one."
          fi

      # ---- Clear leftovers that cause conflicts -----------------------------
      - name: Remove conflicting leftovers (KMS alias & CW log group)
        run: |
          aws kms delete-alias --alias-name "alias/eks/${CLUSTER_NAME}" >/dev/null 2>&1 || true
          aws logs delete-log-group --log-group-name "/aws/eks/${CLUSTER_NAME}/cluster" >/dev/null 2>&1 || true

      # ---- Terraform plan/apply --------------------------------------------
      - name: Terraform Validate
        run: terraform -chdir=infra validate

      - name: Terraform Plan
        run: terraform -chdir=infra plan -out=tfplan

      - name: Terraform Apply
        run: terraform -chdir=infra apply -auto-approve tfplan

      # ---- Build & push image ----------------------------------------------
      - name: Login to ECR
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push image (tag = commit SHA)
        env:
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPO:$IMAGE_TAG .
          docker push $ECR_REGISTRY/$ECR_REPO:$IMAGE_TAG

      # ---- Deploy to EKS ----------------------------------------------------
      - name: Install kubectl
        run: |
          curl -sL https://dl.k8s.io/release/$(curl -sL https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl -o kubectl
          install -m 0755 kubectl /usr/local/bin/kubectl
          kubectl version --client=true

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --name "$CLUSTER_NAME" --region "$AWS_REGION"

      - name: Apply manifests & set image to SHA
        run: |
          kubectl apply -f k8s/deployment.yaml
          kubectl -n "$K8S_NAMESPACE" set image deploy/python-app \
            python-app=$ECR_REGISTRY/$ECR_REPO:${{ github.sha }}

      - name: Wait for rollout
        run: |
          kubectl -n "$K8S_NAMESPACE" rollout status deploy/python-app --timeout=300s
