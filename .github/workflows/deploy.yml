name: Simple Build & Deploy

on:
  push:
    branches: [ main ]

permissions:
  contents: read

env:
  AWS_REGION: us-east-1
  CLUSTER_NAME: devsecops
  NAMESPACE: devsecops
  ECR_REPO: devsecops

jobs:
  deploy:
    runs-on: ubuntu-latest

    # Use static access keys from repo secrets
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Verify AWS keys and identity
        run: |
          set -e
          if [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ]; then
            echo "❌ Missing AWS secrets. Add AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY."; exit 1
          fi
          aws sts get-caller-identity
          echo "✅ AWS creds ok"

      - name: Login to ECR (ensure repo exists)
        run: |
          set -e
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ECR_REGISTRY="${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          echo "ECR_REGISTRY=${ECR_REGISTRY}" >> $GITHUB_ENV
          # create repo if missing
          aws ecr describe-repositories --repository-names "${ECR_REPO}" >/dev/null 2>&1 || \
            aws ecr create-repository --repository-name "${ECR_REPO}" >/dev/null
          # login
          aws ecr get-login-password --region "${AWS_REGION}" \
            | docker login --username AWS --password-stdin "${ECR_REGISTRY}"
          echo "✅ Logged in to ${ECR_REGISTRY}"

      - name: Build & push image
        run: |
          set -e
          IMAGE="${ECR_REGISTRY}/${ECR_REPO}:latest"
          echo "IMAGE=${IMAGE}" >> $GITHUB_ENV
          echo "Building ${IMAGE}"
          docker build -t "${IMAGE}" .
          docker push "${IMAGE}"

      - name: Install kubectl
        run: |
          set -e
          VER="$(curl -L -s https://dl.k8s.io/release/stable.txt)"
          curl -LO "https://dl.k8s.io/release/${VER}/bin/linux/amd64/kubectl"
          chmod +x kubectl && sudo mv kubectl /usr/local/bin/
          kubectl version --client=true

      - name: Update kubeconfig & verify
        run: |
          set -e
          aws eks update-kubeconfig --region "${AWS_REGION}" --name "${CLUSTER_NAME}"
          kubectl get nodes

      - name: Apply manifests
        run: |
          set -e
          kubectl apply -f k8s/test.yaml
          kubectl -n "${NAMESPACE}" get deploy,svc -o wide

      - name: Update deployment image & rollout
        run: |
          set -e
          kubectl -n "${NAMESPACE}" set image deploy/python-app python-app="${IMAGE}" --record
          kubectl -n "${NAMESPACE}" rollout status deploy/python-app --timeout=5m
          kubectl -n "${NAMESPACE}" get pods -o wide

      - name: Show Service address
        run: |
          kubectl get svc -n "${NAMESPACE}" -o wide
