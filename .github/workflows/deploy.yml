name: Build Push Deploy

on:
  push:
    branches:
      - main

# Required so GitHub issues an OIDC token for the AWS role
permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: us-east-1
  CLUSTER_NAME: devsecops
  NAMESPACE: devsecops
  ECR_REPO: devsecops

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # Require OIDC role; fail early if not set
      - name: Verify AWS_ROLE_ARN secret
        env:
          ROLE_ARN: ${{ secrets.AWS_ROLE_ARN }}
        run: |
          if [ -z "$ROLE_ARN" ]; then
            echo "❌ Missing secret AWS_ROLE_ARN. Add it in Settings > Secrets > Actions."; exit 1
          fi
          echo "✅ AWS_ROLE_ARN is set"

      - name: Configure AWS via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      # Install kubectl without external actions
      - name: Install kubectl
        run: |
          set -euo pipefail
          VER="$(curl -L -s https://dl.k8s.io/release/stable.txt)"
          curl -LO "https://dl.k8s.io/release/${VER}/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/
          kubectl version --client=true

      # Login to ECR via CLI (no action needed)
      - name: Login to ECR
        run: |
          set -euo pipefail
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ECR_REGISTRY="${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          aws ecr get-login-password --region "${AWS_REGION}" \
            | docker login --username AWS --password-stdin "${ECR_REGISTRY}"
          echo "ECR_REGISTRY=${ECR_REGISTRY}" >> $GITHUB_ENV

      - name: Build and push image
        run: |
          set -euo pipefail
          IMAGE="${ECR_REGISTRY}/${ECR_REPO}:latest"
          echo "Building $IMAGE"
          docker build -t "$IMAGE" .
          docker push "$IMAGE"
          echo "IMAGE=$IMAGE" >> $GITHUB_ENV

      - name: Update kubeconfig
        run: |
          set -euo pipefail
          aws eks update-kubeconfig --region "${AWS_REGION}" --name "${CLUSTER_NAME}"
          kubectl get nodes

      - name: Apply manifests
        run: |
          set -euo pipefail
          kubectl apply -f k8s/test.yaml

      - name: Set image and rollout
        run: |
          set -euo pipefail
          kubectl -n "${NAMESPACE}" set image deploy/python-app python-app="${IMAGE}" --record
          kubectl -n "${NAMESPACE}" rollout status deploy/python-app --timeout=5m

      - name: Wait for LoadBalancer DNS
        id: lb
        run: |
          set -euo pipefail
          for i in {1..30}; do
            DNS=$(kubectl get svc -n "${NAMESPACE}" python-app-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' || true)
            if [ -n "$DNS" ]; then echo "dns=$DNS" >> $GITHUB_OUTPUT; exit 0; fi
            echo "Waiting for LB... ($i/30)"; sleep 10
          done
          echo "Timed out waiting for LoadBalancer"; exit 1

      - name: Health check
        run: |
          set -euo pipefail
          echo "Hitting http://${{ steps.lb.outputs.dns }}/health"
          for i in {1..30}; do
            code=$(curl -s -o /dev/null -w "%{http_code}" "http://${{ steps.lb.outputs.dns }}/health" || true)
            if [ "$code" = "200" ]; then echo "✅ Health OK"; exit 0; fi
            echo "Health not ready (HTTP $code), retry $i/30"; sleep 5
          done
          echo "Health check failed"; exit 1

      - name: Show Service address
        run: |
          kubectl get svc -n "${NAMESPACE}" -o wide
          echo "Open: http://${{ steps.lb.outputs.dns }}/"
